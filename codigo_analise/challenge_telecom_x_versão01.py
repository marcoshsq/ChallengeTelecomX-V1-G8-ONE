# -*- coding: utf-8 -*-
"""Challenge_Telecom_X_Versão01.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1T5CwX6JniHnCtVm-bu2BU0VcFyCt1OnX

# 📊 Projeto: Análise de Evasão de Clientes da Telecom X

Este projeto faz parte do Challenge Telecom X proposto pela trilha de Data Science do Oracle Next Education (ONE). O objetivo principal é realizar uma análise exploratória dos dados de clientes da Telecom X para entender os fatores relacionados ao churn (evasão de clientes), apoiando futuras estratégias de retenção.

---

## 📌 Etapa 1: Extração dos Dados (E - Extract)

Nesta etapa, realizaremos a extração dos dados no formato `.json`, disponíveis por meio de uma URL pública no GitHub. A ideia é simular a coleta de dados de uma API, mesmo que a fonte seja um arquivo estático.

### 🧰 Importação de Bibliotecas

As bibliotecas abaixo são essenciais para a execução do projeto:

- `pandas` e `numpy`: para manipulação e análise dos dados;
- `matplotlib.pyplot` e `seaborn`: para criação de gráficos e visualizações;
- `scipy.stats`: para análises estatísticas exploratórias;
- `warnings`: para ocultar avisos que não afetam a execução;
- `plt.style.use("ggplot")`: configura um estilo mais limpo e visualmente agradável para os gráficos;
- `sns.set_palette("Set2")`: define uma paleta suave para os gráficos do Seaborn.
"""

# 🧰 Importação de bibliotecas principais

# Manipulação de dados
import pandas as pd
import numpy as np

# Visualização de dados
import matplotlib.pyplot as plt
import seaborn as sns

# Estatísticas e testes
from scipy import stats

# Configuração de estilo para os gráficos
plt.style.use("ggplot")
sns.set_palette("Set2")

# Ignorar avisos desnecessários
import warnings
warnings.filterwarnings('ignore')

# URL do arquivo JSON (emula um endpoint de API)
url = "https://raw.githubusercontent.com/alura-cursos/challenge2-data-science/refs/heads/main/TelecomX_Data.json"

# Carregando os dados
df = pd.read_json(url)

# Exibindo as primeiras linhas
df.head()

"""### 📋 Visão Geral dos Dados

Vamos inspecionar a estrutura inicial dos dados, checar o tamanho do DataFrame, tipos de colunas e verificar se existem dados ausentes.


"""

# Formato do DataFrame
print("Formato do DataFrame:", df.shape)

# Tipos de dados
df.dtypes

# Informações gerais
df.info()

# Amostragem aleatória
df.sample(5)

"""## 🔧 Etapa 2: Transformação dos Dados (T - Transform)

Agora que os dados foram extraídos com sucesso, é hora de entendê-los mais a fundo e prepará-los para as próximas etapas da análise. Nesta etapa vamos:

- Compreender a estrutura das colunas e tipos de dados;
- Identificar e tratar inconsistências;
- Expandir colunas compostas (como dicionários aninhados);
- Criar novas variáveis úteis, como o faturamento diário;
- (Opcional) Padronizar e transformar os dados para facilitar a análise futura.

✅ Ao final desta etapa, teremos um dataset limpo, estruturado e pronto para análise exploratória.

---

#### Dicionário de dados

* `customerID`: número de identificação único de cada cliente
* `Churn`: se o cliente deixou ou não a empresa
* `gender`: gênero (masculino e feminino)
* `SeniorCitizen`: informação sobre um cliente ter ou não idade igual ou maior que 65 anos
* `Partner`:  se o cliente possui ou não um parceiro ou parceira
* `Dependents`: se o cliente possui ou não dependentes
* `tenure`:  meses de contrato do cliente
* `PhoneService`: assinatura de serviço telefônico
* `MultipleLines`: assisnatura de mais de uma linha de telefone
* `InternetService`: assinatura de um provedor internet
* `OnlineSecurity`: assinatura adicional de segurança online
* `OnlineBackup`: assinatura adicional de backup online
* `DeviceProtection`: assinatura adicional de proteção no dispositivo
* `TechSupport`: assinatura adicional de suporte técnico, menos tempo de espera
* `StreamingTV`: assinatura de TV a cabo
* `StreamingMovies`: assinatura de streaming de filmes
* `Contract`: tipo de contrato
* `PaperlessBilling`: se o cliente prefere receber online a fatura
* `PaymentMethod`: forma de pagamento
* `Charges.Monthly`: total de todos os serviços do cliente por mês
* `Charges.Total`: total gasto pelo cliente

### 🧩 2.1 Conhecendo a Estrutura dos Dados

Algumas colunas do dataset não estão planas, ou seja, contêm estruturas do tipo `dict` com várias sub-informações. Vamos descompactar essas colunas e integrá-las ao DataFrame principal para facilitar a análise.

Além disso, faremos uma análise exploratória rápida para:

- Verificar o tipo de cada coluna;
- Observar categorias disponíveis em variáveis qualitativas;
- Consultar o dicionário de dados oficial, caso necessário.

---
"""

# 📋 Verificando o tipo de dado de cada coluna
print("Tipos de dados por coluna:\n")
print(df.dtypes)

# 🔍 Verificando amostras das colunas com dicionários
# Vamos ver o conteúdo da primeira linha de cada coluna aninhada

print("Exemplo da coluna 'customer':\n", df["customer"].iloc[0])
print("\nExemplo da coluna 'phone':\n", df["phone"].iloc[0])
print("\nExemplo da coluna 'internet':\n", df["internet"].iloc[0])
print("\nExemplo da coluna 'account':\n", df["account"].iloc[0])

"""### 🧩 Conclusões: 2.1 Conhecendo a Estrutura dos Dados

Nesta etapa, exploramos a estrutura interna do dataset e identificamos colunas que precisam de transformação futura.

- O dataset possui 7267 registros e 6 colunas.
- Das 6 colunas, 4 contêm dados estruturados como dicionários:
  - `customer`, `phone`, `internet`, `account`
- Essas colunas precisam ser "explodidas" futuramente para facilitar a análise.

No momento, apenas identificamos essa estrutura. As transformações serão feitas na próxima etapa (2.3).

### 🧹 2.2 Verificando Inconsistências

Nesta etapa, procuramos:

- Valores nulos;
- Duplicidades;
- Categorias inconsistentes (ex: espaços em branco, letras maiúsculas e minúsculas misturadas);
- Tipos incorretos (ex: números como string, datas não reconhecidas, etc.).

---
"""

# 🔍 Verificando a quantidade de valores nulos por coluna
df.isnull().sum()

# 💯 Porcentagem de valores nulos por coluna
(df.isnull().sum() / df.shape[0]) * 100

# 🔁 Verificando se há IDs de cliente duplicados
df['customerID'].duplicated().sum()

# 🔍 Verificando os valores únicos de 'Churn'
df['Churn'].unique()

# 📊 Frequência de valores de 'Churn'
df['Churn'].value_counts()

# 🧪 Verificando se há campos com string vazia em todas as colunas de nível superior
for col in df.columns:
    if df[col].dtype == 'object':
        count_empty = (df[col] == '').sum()
        if count_empty > 0:
            print(f"Coluna '{col}' possui {count_empty} valores vazios ('').")

"""### 🔧 2.3 Tratando as Inconsistências

Uma vez identificados os problemas, vamos corrigi-los:

- Preencher ou excluir valores ausentes (caso necessário);
- Corrigir categorias (padronizando letras, removendo espaços);
- Explodir os dicionários em colunas separadas;
- Garantir coerência nos tipos de dados.

---
"""

# 🧹 Substituindo valores vazios por NaN em 'Churn'
df['Churn'] = df['Churn'].replace('', np.nan)

# 🔁 Verificando novamente os valores únicos
df['Churn'].value_counts(dropna=False)

# 🧱 Separando as colunas que estão em formato de dicionário
df_customer = pd.json_normalize(df['customer'])
df_phone = pd.json_normalize(df['phone'])
df_internet = pd.json_normalize(df['internet'])
df_account = pd.json_normalize(df['account'])

# 🔗 Concatenando os dados transformados ao DataFrame original
df = pd.concat([
    df.drop(columns=['customer', 'phone', 'internet', 'account']),
    df_customer,
    df_phone,
    df_internet,
    df_account
], axis=1)

# 👀 Visualizando as 5 primeiras linhas do novo DataFrame
df.head()

# 📏 Verificando o novo shape
df.shape

"""### 💡 2.4 Criando a Coluna `Contas_Diarias`

Para ter uma visão mais granular sobre o faturamento dos clientes, criaremos a coluna `Contas_Diarias`, calculando o valor médio diário com base na coluna `Charges.Monthly`:

```python
df["Contas_Diarias"] = df["Charges.Monthly"] / 30
"""

# 🔍 Conferindo os tipos novamente
df.dtypes

# 🔁 Convertendo Charges.Total para float (coercivo)
df['Charges.Total'] = pd.to_numeric(df['Charges.Total'], errors='coerce')

# 🔍 Verificando se houve valores não conversíveis (viraram NaN)
df['Charges.Total'].isnull().sum()

# 🔍 Conferindo os tipos novamente
df.dtypes

# 💡 Criando a coluna Contas_Diarias
df['Contas_Diarias'] = df['Charges.Monthly'] / 30

# 👀 Visualizando as 5 primeiras linhas
df[['Charges.Monthly', 'Contas_Diarias']].head()

"""### 🔄 2.5 Padronização e Transformação de Dados (Opcional)
Caso necessário, aplicaremos:

- Tradução ou renomeação de colunas;
- Conversão de variáveis categóricas para numéricas (por exemplo, "Yes"/"No" → 1/0);
- Padronização de nomenclaturas (ex: substituição de espaços por underscore, tudo em minúsculas).

Esta etapa melhora a clareza do dataset e facilita a aplicação de modelos preditivos posteriormente.
"""

# 🔍 Verificando colunas com valores "Yes"/"No"
for col in df.columns:
    if df[col].dtype == 'object':
        uniques = df[col].dropna().unique()
        if set(uniques).issubset({'Yes', 'No'}):
            print(f"Coluna binária detectada: {col}")

# 🔁 Convertendo colunas binárias para 0 e 1
cols_binarias = ['Churn', 'Partner', 'Dependents', 'PhoneService', 'PaperlessBilling']

for col in cols_binarias:
    df[col] = df[col].map({'Yes': 1, 'No': 0})

# ✅ Verificando os valores únicos após conversão
for col in cols_binarias:
    print(f"{col}: {df[col].unique()}")

# 🔡 Padronizando texto: minúsculas + remoção de espaços extras
for col in df.select_dtypes(include='object').columns:
    if col != 'customerID':
        df[col] = df[col].str.strip().str.lower()

df[['gender', 'MultipleLines', 'InternetService']].sample(5)

# 🏷️ Renomeando colunas para o padrão snake_case
df = df.rename(columns={
    'customerID': 'customer_id',
    'SeniorCitizen': 'is_senior',
    'Charges.Monthly': 'charges_monthly',
    'Charges.Total': 'charges_total',
    'Contas_Diarias': 'daily_charges'
})

df.rename(columns={
    'Contract': 'contract',
    'PaperlessBilling': 'paperless_billing',
    'PaymentMethod': 'payment_method',
    'InternetService': 'internet_service',
    'OnlineSecurity': 'online_security',
    'OnlineBackup': 'online_backup',
    'DeviceProtection': 'device_protection',
    'TechSupport': 'tech_support',
    'StreamingTV': 'streaming_tv',
    'StreamingMovies': 'streaming_movies',
    'MultipleLines': 'multiple_lines',
    'PhoneService': 'phone_service'
}, inplace=True)

df.columns

"""# 🔍 Etapa 3: Análise Exploratória de Dados ((L - Load & Analysis))

Nesta etapa, vamos explorar o comportamento dos clientes e identificar padrões associados à evasão (churn). A análise será dividida em blocos temáticos, acompanhada de perguntas orientadoras.

---

## 📊 3.1 Análise Descritiva Geral

Vamos começar com uma visão geral do dataset, observando medidas como média, mediana, desvio padrão e valores mínimos/máximos.

**Perguntas que queremos responder:**
- Qual é o gasto médio mensal dos clientes?
- Qual a mediana do tempo de permanência (tenure)?
- Há muitos outliers nas variáveis de valor?

---
"""

# 📊 Estatísticas descritivas das variáveis numéricas
df.describe().T

# 🔍 Selecionando colunas específicas
df[['tenure', 'charges_monthly', 'charges_total', 'daily_charges']].describe().T

# 🧠 Insights automatizados usando f-strings
media_charges = df['charges_monthly'].mean()
mediana_tenure = df['tenure'].median()
churn_rate = df['Churn'].mean() * 100
media_total = df['charges_total'].mean()
max_total = df['charges_total'].max()
senior_pct = df['is_senior'].mean() * 100
partner_pct = df['Partner'].mean() * 100
dependents_pct = df['Dependents'].mean() * 100
phone_pct = df['PhoneService'].mean() * 100

# Principais Observações da Análise Descritiva
print(f"""
📊 Principais Observações da Análise Descritiva:

- Churn: Aproximadamente {churn_rate:.1f}% dos clientes cancelaram — um índice significativo.
- Tenure: A mediana é de {mediana_tenure:.0f} meses — metade dos clientes permanece por mais de 2 anos.
- Charges Monthly: Gasto mensal médio de R$ {media_charges:.2f}.
- Charges Total: Média de R$ {media_total:.2f} com um máximo de R$ {max_total:.2f}.
- SeniorCitizen: Apenas {senior_pct:.1f}% dos clientes têm 65 anos ou mais.
- Partner: {partner_pct:.1f}% possuem parceiro(a).
- Dependents: {dependents_pct:.1f}% possuem dependentes.
- PhoneService: {phone_pct:.1f}% dos clientes possuem serviço telefônico.
""")

from IPython.display import Markdown

Markdown("""
### 📊 Principais Observações da Análise Descritiva

- **Churn**: Cerca de **26,5%** dos clientes cancelaram — um índice significativo.
- **Tenure**: A mediana é de **29 meses** — metade dos clientes permanece por mais de 2 anos.
- **Charges Monthly**: Gasto mensal médio de **R$ 64,72**, com desvio padrão de **R$ 30** — há bastante variação.
- **Charges Total**: Média de **R$ 2.280** com máximo de **R$ 8.684** — possível presença de outliers.
- **Daily Charges**: Calculado com base no gasto mensal, apresenta distribuição coerente.
- **SeniorCitizen**: Apenas **16%** dos clientes têm 65 anos ou mais.
- **Partner e Dependents**: 48% possuem parceiro(a) e apenas 30% possuem dependentes.
- **PhoneService**: A maioria dos clientes (**90%**) tem serviço telefônico.
""")

"""## 📈 3.2 Distribuição Geral da Evasão

Nesta etapa, analisamos como a variável `churn` está distribuída entre os clientes.

**Perguntas que queremos responder:**
- Qual é a proporção de clientes que cancelaram versus os que permaneceram?
- O churn é um problema significativo na base de clientes?

---
"""

# 📊 Distribuição da Evasão com gráfico de barras
plt.figure(figsize=(12, 6))
sns.countplot(x='Churn', data=df, palette='Set2')
plt.title('Distribuição Geral da Evasão de Clientes')
plt.ylabel('Quantidade de Clientes')
plt.xticks([0, 1], ['Permaneceu', 'Cancelou'])
plt.grid(axis='y', linestyle='--', alpha=0.5)
plt.tight_layout()
plt.show()

# 📉 Proporção de churn
cancelou = df['Churn'].sum()
total = df['Churn'].notnull().sum()
proporcao = cancelou / total * 100

print(f"Aproximadamente {proporcao:.2f}% dos clientes cancelaram o serviço.")

print(f"""
🎯 Interpretação:

- Cerca de {proporcao:.2f}% dos clientes cancelaram seus serviços.
- Esse valor é considerado **alto** no mercado, indicando que a empresa enfrenta um problema sério de retenção.
- Clientes ativos (Churn = 0) representam a maioria, mas o volume de evasão é relevante e merece investigação.
""")

"""## 🔠 3.3 Evasão por Variáveis Categóricas

Aqui investigamos como a evasão varia de acordo com variáveis como `gender`, `contract`, `payment_method`, etc.

**Perguntas que queremos responder:**
- Certos perfis (ex: tipo de contrato ou método de pagamento) têm maior probabilidade de churn?
- Há diferenças de evasão entre gêneros ou faixas de serviço?

---
"""

# 📊 Função para plotar a relação entre churn e qualquer variável categórica
def plot_churn_by_category(col):
    plt.figure(figsize=(15, 6))
    sns.countplot(data=df, x=col, hue='Churn', palette='Set2')
    plt.title(f"Evasão por {col}")
    plt.xlabel(col.replace("_", " ").title())
    plt.ylabel("Quantidade de Clientes")
    plt.legend(title='Churn', labels=['Permaneceu (0)', 'Cancelou (1)'])
    plt.xticks(rotation=30)
    plt.grid(axis='y', linestyle='--', alpha=0.5)
    plt.tight_layout()
    plt.show()

plot_churn_by_category('payment_method')

plot_churn_by_category('contract')

# 💡 Observação sobre churn por tipo de contrato
churn_by_contract = df.groupby('contract')['Churn'].mean().sort_values(ascending=False)

print(f"""
📊 Evasão por Tipo de Contrato:

- Contrato com maior churn: {churn_by_contract.index[0].capitalize()} ({churn_by_contract.iloc[0]*100:.2f}% de cancelamento)
- Contrato com menor churn: {churn_by_contract.index[-1].capitalize()} ({churn_by_contract.iloc[-1]*100:.2f}% de cancelamento)

🧠 Insight:
Clientes com contrato '{churn_by_contract.index[0]}' cancelam **muito mais** do que os que têm contrato '{churn_by_contract.index[-1]}'.
Isso sugere que contratos mais longos (como 'two year') ajudam na **retenção**.
""")

plot_churn_by_category('payment_method')

plot_churn_by_category('internet_service')

plot_churn_by_category('tech_support')

plot_churn_by_category('online_security')

plot_churn_by_category('streaming_tv')

plot_churn_by_category('gender')

# 🧠 Função para gerar insights textuais com f-string
def churn_insight_por_categoria(col):
    churn_por_categoria = df.groupby(col)['Churn'].mean().sort_values(ascending=False)

    print(f"""
📊 Evasão por {col.replace('_', ' ').title()}:

- Categoria com maior churn: {churn_por_categoria.index[0].capitalize()} ({churn_por_categoria.iloc[0]*100:.2f}% de cancelamento)
- Categoria com menor churn: {churn_por_categoria.index[-1].capitalize()} ({churn_por_categoria.iloc[-1]*100:.2f}% de cancelamento)

🧠 Insight:
Clientes da categoria '{churn_por_categoria.index[0]}' apresentam maior tendência ao cancelamento, enquanto aqueles da categoria '{churn_por_categoria.index[-1]}' são mais propensos à retenção.
""")

churn_insight_por_categoria('payment_method')

churn_insight_por_categoria('internet_service')

churn_insight_por_categoria('tech_support')

churn_insight_por_categoria('online_security')

churn_insight_por_categoria('streaming_tv')

"""## 🔢 3.4 Evasão por Variáveis Numéricas

Vamos observar como a evasão se distribui em relação a variáveis como `charges_total`, `charges_monthly`, `tenure`, e `daily_charges`.

**Perguntas que queremos responder:**
- Clientes com maior tempo de casa tendem a sair menos?
- Clientes com valores mais altos de conta estão mais propensos ao cancelamento?

---
"""

# 📊 Função para comparar variáveis numéricas por churn
def plot_box_by_churn(numeric_col):
    plt.figure(figsize=(12, 6))
    sns.boxplot(data=df, x='Churn', y=numeric_col, palette='Set2')
    plt.title(f'{numeric_col.replace("_", " ").title()} vs Churn')
    plt.xlabel('Churn (0 = Permaneceu, 1 = Cancelou)')
    plt.ylabel(numeric_col.replace("_", " ").title())
    plt.grid(axis='y', linestyle='--', alpha=0.5)
    plt.tight_layout()
    plt.show()

plot_box_by_churn('tenure')

plot_box_by_churn('charges_monthly')

plot_box_by_churn('charges_total')

plot_box_by_churn('daily_charges')

# 🧠 Gera observação automática para variáveis numéricas com base em churn
def churn_insight_por_variavel_numerica(col):
    media_cancelou = df[df['Churn'] == 1][col].mean()
    media_ficou = df[df['Churn'] == 0][col].mean()

    print(f"""
📊 Comparação de {col.replace('_', ' ').title()} entre grupos:

- Média para clientes que **cancelaram**: {media_cancelou:.2f}
- Média para clientes que **permaneceram**: {media_ficou:.2f}

🧠 Insight:
Clientes que cancelaram tendem a ter valores de '{col.replace('_', ' ').lower()}' { 'menores' if media_cancelou < media_ficou else 'maiores' } do que os que permaneceram.
""")

churn_insight_por_variavel_numerica('tenure')

churn_insight_por_variavel_numerica('charges_total')

"""## 🔗 3.5 (Extra) Correlação entre Variáveis

Como passo opcional, vamos explorar relações lineares entre variáveis numéricas e o churn.

**Perguntas que queremos responder:**
- Existe correlação entre `tenure` e `churn`?
- A quantidade de serviços contratados se relaciona com a evasão?

---
"""

# 🔗 Selecionar apenas colunas numéricas
df_num = df.select_dtypes(include=['int64', 'float64'])

# 📊 Matriz de correlação
corr = df_num.corr()

# 🔥 Heatmap
plt.figure(figsize=(20, 15))
sns.heatmap(corr, annot=True, fmt=".2f", cmap="coolwarm", vmin=-1, vmax=1)
plt.title("🔗 Correlação entre Variáveis Numéricas")
plt.tight_layout()
plt.show()

# 🧠 Interpretando as principais correlações com Churn
corr_com_churn = corr['Churn'].drop('Churn').sort_values()

# Top 3 correlações negativas
mais_negativas = corr_com_churn.head(3)
# Top 3 correlações positivas
mais_positivas = corr_com_churn.tail(3)

print(f"""
📊 Principais Correlações com Churn:

🔻 Correlações Negativas (quanto maior o valor, menor a chance de churn):
- {mais_negativas.index[0]}: {mais_negativas.iloc[0]:.2f}
- {mais_negativas.index[1]}: {mais_negativas.iloc[1]:.2f}
- {mais_negativas.index[2]}: {mais_negativas.iloc[2]:.2f}

🔺 Correlações Positivas (quanto maior o valor, maior a chance de churn):
- {mais_positivas.index[0]}: {mais_positivas.iloc[0]:.2f}
- {mais_positivas.index[1]}: {mais_positivas.iloc[1]:.2f}
- {mais_positivas.index[2]}: {mais_positivas.iloc[2]:.2f}

🧠 Insight:
A variável com maior correlação negativa com churn é '{mais_negativas.index[0]}', sugerindo que quanto mais ela aumenta, menor é a evasão. Já '{mais_positivas.index[-1]}' apresenta correlação positiva, indicando possível relação direta com cancelamento.
""")

"""# 🧾 Relatório Final – Análise de Evasão de Clientes (Churn)

## 🎯 Objetivo

O projeto teve como objetivo analisar os dados da operadora fictícia **Telecom X** para entender os principais fatores relacionados à evasão de clientes (churn). A partir de análises descritivas e exploratórias, buscou-se identificar perfis e padrões de comportamento associados ao cancelamento dos serviços.

---

## 🧹 Limpeza e Transformação dos Dados

- Os dados foram extraídos de um arquivo JSON e transformados de uma estrutura aninhada para um formato tabular.
- Foram tratadas inconsistências como valores ausentes em `Churn` e tipos incorretos em `charges_total`.
- As colunas foram padronizadas para `snake_case` e variáveis binárias foram convertidas para `0` e `1`.

---

## 📊 Principais Análises e Insights

- **Churn** atinge cerca de **26,5% dos clientes**, índice considerado **alto** para o setor.
- Clientes com **contrato mensal (month-to-month)** apresentaram o maior índice de evasão (**42,7%**).
- Clientes com contratos de **dois anos** tiveram churn **inferior a 3%**, indicando forte relação entre **tempo de fidelização** e retenção.
- Variáveis como `tenure` e `charges_total` mostraram correlação negativa com churn, enquanto `charges_monthly` e `paperless_billing` mostraram correlação positiva.
- Clientes com menor tempo de permanência e menor valor total gasto são os que mais cancelam.

---

## ✅ Recomendações Estratégicas

Com base nos padrões identificados, sugerimos as seguintes ações para redução do churn:

1. **Incentivar contratos de longo prazo** (ex: "dois anos") com benefícios exclusivos ou descontos progressivos.
2. **Criar campanhas de retenção para clientes novos**, principalmente nos primeiros 12 meses — período crítico de evasão.
3. **Monitorar clientes com contas mensais altas**, pois estão mais propensos a cancelar. Avaliar percepção de valor desses serviços.
4. **Avaliar o impacto da fatura digital**: usuários de `paperless_billing` têm maior churn. Isso pode indicar um perfil mais impaciente, digital-first — ideal para testes A/B com experiências personalizadas.
5. **Explorar perfis familiares com dependentes** como segmento estratégico — tendem a ser mais fiéis.

---

## 🧠 Conclusão

A análise permitiu identificar padrões claros de comportamento associados à evasão. O entendimento desses fatores é essencial para o desenvolvimento de estratégias mais direcionadas de retenção, que poderão ser aprofundadas com modelos preditivos em uma próxima etapa.
"""